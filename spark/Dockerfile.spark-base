FROM apache/spark:3.4.2

ARG ICEBERG_VER=1.5.2
ARG NESSIE_VER=0.74.0
ARG HADOOP_AWS_VER=3.3.4
ARG AWS_SDK_VER=1.12.262

USER root

RUN apt-get update && apt-get install -y --no-install-recommends \
      curl \
      python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Install pyspark to match Spark version
RUN pip3 install --no-cache-dir pyspark==3.4.2

# Pre-create Spark directories
RUN mkdir -p /opt/spark/work /opt/spark/logs /opt/spark/jobs && \
    chown -R 1001:1001 /opt/spark

# Download required JARs into Apache Spark's jars folder
RUN curl -fsSL -o /opt/spark/jars/iceberg-spark-runtime-3.4_2.12-${ICEBERG_VER}.jar \
      https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.4_2.12/${ICEBERG_VER}/iceberg-spark-runtime-3.4_2.12-${ICEBERG_VER}.jar && \
    curl -fsSL -o /opt/spark/jars/nessie-spark-extensions-3.4_2.12-${NESSIE_VER}.jar \
      https://repo1.maven.org/maven2/org/projectnessie/nessie-integrations/nessie-spark-extensions-3.4_2.12/${NESSIE_VER}/nessie-spark-extensions-3.4_2.12-${NESSIE_VER}.jar && \
    curl -fsSL -o /opt/spark/jars/hadoop-aws-${HADOOP_AWS_VER}.jar \
      https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/${HADOOP_AWS_VER}/hadoop-aws-${HADOOP_AWS_VER}.jar && \
    curl -fsSL -o /opt/spark/jars/aws-java-sdk-bundle-${AWS_SDK_VER}.jar \
      https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/${AWS_SDK_VER}/aws-java-sdk-bundle-${AWS_SDK_VER}.jar

# Copy job scripts
COPY spark/jobs/run-append.py /opt/spark/jobs/run-append.py
COPY spark/jobs/run-init.sh   /opt/spark/jobs/run-init.sh

# Copy SQL schemas
COPY sql /sql

RUN chmod +x /opt/spark/jobs/run-init.sh

# Ensure UID 1001 resolves to a name
RUN echo "spark:x:1001:1001:Spark User:/opt/spark:/bin/bash" >> /etc/passwd

USER 1001